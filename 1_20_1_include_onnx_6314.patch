diff --git a/cmake/patches/onnx/onnx.patch b/cmake/patches/onnx/onnx.patch
index 4ca96834c6..5f098ab9a9 100644
--- a/cmake/patches/onnx/onnx.patch
+++ b/cmake/patches/onnx/onnx.patch
@@ -1027,3 +1027,65 @@ index 75280f6c..5543fda0 100644
          N, C = 3, 4
          graph = self._make_graph(
 
+--- a/onnx/defs/tensor/old.cc
++++ b/onnx/defs/tensor/old.cc
+@@ -2757,7 +2757,6 @@ ONNX_OPERATOR_SET_SCHEMA(
+             return;
+           }
+
+-          ctx.getOutputType(0)->mutable_tensor_type()->mutable_shape();
+           const auto& input_shape = ctx.getInputType(0)->tensor_type().shape();
+           const auto input_ndim = input_shape.dim_size();
+           std::vector<int64_t> axes;
+@@ -2776,6 +2775,7 @@ ONNX_OPERATOR_SET_SCHEMA(
+             return axis < 0 ? axis + input_ndim : axis;
+           });
+
++          ctx.getOutputType(0)->mutable_tensor_type()->mutable_shape();
+           for (int i = 0; i < input_ndim; ++i) {
+             if (std::find(axes.begin(), axes.end(), i) != axes.end()) {
+               if (input_shape.dim(i).has_dim_value() && input_shape.dim(i).dim_value() != 1) {
+@@ -5096,7 +5096,6 @@ ONNX_OPERATOR_SET_SCHEMA(
+             return;
+           }
+
+-          ctx.getOutputType(0)->mutable_tensor_type()->mutable_shape();
+           const auto& input_shape = ctx.getInputType(0)->tensor_type().shape();
+           const auto input_ndim = input_shape.dim_size();
+           std::vector<int64_t> axes;
+@@ -5111,6 +5110,7 @@ ONNX_OPERATOR_SET_SCHEMA(
+             }
+           }
+
++          ctx.getOutputType(0)->mutable_tensor_type()->mutable_shape();
+           for (int i = 0, j = 0; i < input_shape.dim_size(); ++i) {
+             if (static_cast<size_t>(j) < axes.size() && axes[j] == i) {
+               if (input_shape.dim(i).has_dim_value() && input_shape.dim(i).dim_value() != 1) {
+diff --git a/onnx/test/shape_inference_test.py b/onnx/test/shape_inference_test.py
+index 9e6b96b5b49..b0cdace4558 100644
+--- a/onnx/test/shape_inference_test.py
++++ b/onnx/test/shape_inference_test.py
+@@ -1680,6 +1680,23 @@ def test_squeeze_no_axes_opset11(self) -> None:
+             graph, [make_tensor_value_info("y", TensorProto.FLOAT, (3, 2))]
+         )
+
++    def test_squeeze_no_axes_dynamic_input_opset11(self) -> None:
++        graph = self._make_graph(
++            [
++                ("x", TensorProto.FLOAT, (1, 3, 1, None, 2, 1)),
++            ],
++            [make_node("Squeeze", ["x"], "y")],
++            [],
++        )
++        operatorsetid = OperatorSetIdProto()
++        operatorsetid.domain = ""
++        operatorsetid.version = 11
++        self._assert_inferred(
++            graph,
++            [make_tensor_value_info("y", TensorProto.FLOAT, None)],
++            opset_imports=[operatorsetid],
++        )
++
+     def test_unsqueeze_regular(self) -> None:
+         graph = self._make_graph(
+             [("x", TensorProto.FLOAT, (3, 2)), ("axes", TensorProto.INT64, (4,))],
diff --git a/js/web/package.json b/js/web/package.json
index d5dba18c14..c82ad024c3 100644
--- a/js/web/package.json
+++ b/js/web/package.json
@@ -13,7 +13,7 @@
     "flatbuffers": "^1.12.0",
     "guid-typescript": "^1.0.9",
     "long": "^5.2.3",
-    "onnxruntime-common": "file:../common",
+    "onnxruntime-common": "../common",
     "platform": "^1.3.6",
     "protobufjs": "^7.2.4"
   },
